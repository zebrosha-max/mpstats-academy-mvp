---
phase: 02-ai-question-generation
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - packages/api/src/routers/diagnostic.ts
  - apps/web/src/app/(main)/diagnostic/session/page.tsx
autonomous: true

must_haves:
  truths:
    - "startSession calls generateDiagnosticQuestions with fallback to mock — user always gets 15 questions"
    - "If LLM is unavailable or times out, diagnostic still works with mock questions"
    - "Rate limit of 50 req/hour per user enforced — excess returns TOO_MANY_REQUESTS error"
    - "User sees spinner 'Готовим вопросы...' while questions generate"
    - "FINANCE category questions always come from mock bank (no course data)"
  artifacts:
    - path: "packages/api/src/routers/diagnostic.ts"
      provides: "Async question generation in startSession with rate limiting and fallback"
      contains: "generateDiagnosticQuestions"
    - path: "apps/web/src/app/(main)/diagnostic/session/page.tsx"
      provides: "Loading state with spinner during question generation"
      contains: "Готовим вопросы"
  key_links:
    - from: "packages/api/src/routers/diagnostic.ts"
      to: "packages/ai/src/question-generator.ts"
      via: "import generateDiagnosticQuestions from @mpstats/ai"
      pattern: "generateDiagnosticQuestions"
    - from: "packages/api/src/routers/diagnostic.ts"
      to: "packages/api/src/mocks/questions.ts"
      via: "getMockQuestionsForCategory passed as fallback callback"
      pattern: "getMockQuestionsForCategory"
    - from: "packages/api/src/routers/diagnostic.ts"
      to: "rate limiter in-memory Map"
      via: "checkRateLimit before generation"
      pattern: "checkRateLimit.*50.*3600000"
---

<objective>
Integrate AI question generation into the diagnostic router with rate limiting and graceful fallback.

Purpose: Wire the question generator from Plan 01 into the startSession mutation so users get AI-generated questions. Add rate limiting (50/hour) and ensure the diagnostic never fails — always falls back to mock questions.
Output: Updated diagnostic router, loading UI state
</objective>

<execution_context>
@C:/Users/Zebrosha/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Zebrosha/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ai-question-generation/02-RESEARCH.md
@.planning/phases/02-ai-question-generation/02-01-SUMMARY.md

@packages/api/src/routers/diagnostic.ts
@packages/api/src/mocks/questions.ts
@apps/web/src/app/(main)/diagnostic/session/page.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rate limiter and async question generation in diagnostic router</name>
  <files>
    packages/api/src/routers/diagnostic.ts
  </files>
  <action>
**1. Add in-memory rate limiter** at the top of diagnostic.ts (after imports):

```typescript
// Simple sliding window rate limiter for question generation
const generationRateLimits = new Map<string, number[]>();

function checkRateLimit(userId: string, maxRequests: number = 50, windowMs: number = 3600000): boolean {
  const now = Date.now();
  const timestamps = generationRateLimits.get(userId) || [];
  const recent = timestamps.filter(t => now - t < windowMs);
  if (recent.length >= maxRequests) return false;
  recent.push(now);
  generationRateLimits.set(userId, recent);
  return true;
}
```

Store in `globalThis` for persistence across hot reloads (same pattern as activeSessionQuestions).

**2. Update startSession mutation** to use async AI question generation:

Replace the synchronous `getBalancedQuestions(QUESTIONS_PER_SESSION)` call with:

```typescript
// Rate limit check
if (!checkRateLimit(ctx.user.id)) {
  throw new TRPCError({
    code: 'TOO_MANY_REQUESTS',
    message: 'Слишком много запросов на диагностику. Попробуйте через час.',
  });
}

// Generate questions with AI, fallback to mock
let questions: DiagnosticQuestion[];
try {
  questions = await generateDiagnosticQuestions(
    (category, count) => getMockQuestionsForCategory(category, count)
  );
} catch (error) {
  // Complete fallback: if generateDiagnosticQuestions itself throws,
  // use fully mock-based questions
  console.error('AI question generation failed completely, using mock:', error);
  questions = getBalancedQuestions(QUESTIONS_PER_SESSION);
}
```

**3. Update imports:**
- Add `import { generateDiagnosticQuestions } from '@mpstats/ai';`
- Change mock import to include `getMockQuestionsForCategory`: `import { getBalancedQuestions, getMockQuestionsForCategory } from '../mocks/questions';`

**Key behavior:**
- Rate limit check BEFORE any LLM call (prevents cost abuse).
- `generateDiagnosticQuestions` handles per-category fallback internally (via the callback).
- Outer try/catch is safety net for unexpected errors (network, import issues).
- If everything fails, `getBalancedQuestions` provides fully mock experience.
- The mutation is now async (it already was — `async ({ ctx })` — but the question generation adds real async work).
  </action>
  <verify>
- `pnpm --filter @mpstats/api typecheck` passes
- Rate limiter: calling checkRateLimit 50 times returns true, 51st returns false
- Import of generateDiagnosticQuestions from @mpstats/ai resolves correctly
- startSession still returns same shape: `{ id, status, totalQuestions, currentQuestion }`
  </verify>
  <done>
- startSession uses AI-generated questions as primary source
- Rate limiting enforced at 50 req/hour per user
- Triple fallback chain: AI per-category -> mock per-category -> full mock
- No breaking changes to startSession response shape
- Console logging on fallback for debugging
  </done>
</task>

<task type="auto">
  <name>Task 2: Loading state UI for question generation</name>
  <files>
    apps/web/src/app/(main)/diagnostic/session/page.tsx
  </files>
  <action>
Update the diagnostic session page to show a proper loading state while questions are being generated by AI.

**Current behavior:** The page calls `startSession` mutation and shows a generic loading spinner.

**New behavior:** Show a contextual loading message:
- While startSession is pending: display "Готовим вопросы..." with a spinner/pulsing animation.
- Use existing Tailwind animation classes (animate-pulse or the custom animate-fade-in from Sprint 2.5).
- Message text: "Готовим вопросы..." with a subtext "AI подбирает вопросы на основе учебных материалов" in a smaller, muted font.
- Keep the existing loading UI pattern from the page but replace generic text with the diagnostic-specific message.
- If startSession takes >3 seconds, optionally add secondary text "Это может занять несколько секунд..." (use setTimeout in useEffect).

**Do NOT show** a category badge during the test (per discretion recommendation in RESEARCH.md — reveals which skill is being tested).

Keep all existing functionality intact. This is purely a UI polish for the generation wait time.
  </action>
  <verify>
- `pnpm build` passes (or at minimum `pnpm --filter web typecheck`)
- Visual check: page shows "Готовим вопросы..." during startSession mutation
- After questions load, normal diagnostic flow continues unchanged
  </verify>
  <done>
- Diagnostic session page shows "Готовим вопросы..." with spinner during AI generation
- Secondary "AI подбирает вопросы..." subtext visible
- No category badges shown during test
- Existing diagnostic flow unchanged after questions load
  </done>
</task>

</tasks>

<verification>
1. `pnpm --filter @mpstats/api typecheck` — no errors
2. `pnpm --filter web typecheck` — no errors
3. Full diagnostic flow: startSession -> getSessionState -> submitAnswer -> getResults all still work
4. Rate limit: 51st startSession call within 1 hour returns TOO_MANY_REQUESTS
5. If OPENROUTER_API_KEY is missing/invalid, diagnostic falls back to mock questions (doesn't crash)
6. Loading UI shows "Готовим вопросы..." text
</verification>

<success_criteria>
- Diagnostic uses AI-generated questions when LLM is available
- Diagnostic works with mock questions when LLM is unavailable (graceful degradation)
- Rate limiting prevents abuse (50 req/hour per user)
- User sees informative loading state during question generation
- No regression in existing diagnostic flow
</success_criteria>

<output>
After completion, create `.planning/phases/02-ai-question-generation/02-02-SUMMARY.md`
</output>
