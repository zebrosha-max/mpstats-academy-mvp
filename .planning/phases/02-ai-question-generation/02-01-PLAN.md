---
phase: 02-ai-question-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/ai/src/question-schema.ts
  - packages/ai/src/question-generator.ts
  - packages/ai/src/index.ts
  - packages/api/src/mocks/questions.ts
  - scripts/seed/seed-mock-questions.ts
autonomous: true

must_haves:
  truths:
    - "generateDiagnosticQuestions() returns 15 DiagnosticQuestion objects (3 per category)"
    - "Each generated question has 4 options, 1 correctIndex, explanation, difficulty, skillCategory"
    - "LLM output is validated with Zod — invalid responses are rejected cleanly"
    - "Options are shuffled after LLM generation to avoid index bias"
    - "FINANCE category (no course data) falls through to mock immediately"
    - "Mock question bank has 100 questions (20 per category) for fallback"
  artifacts:
    - path: "packages/ai/src/question-schema.ts"
      provides: "Zod schema + JSON Schema for structured LLM output"
      exports: ["generatedQuestionSchema", "generatedQuestionsArraySchema", "questionJsonSchema"]
    - path: "packages/ai/src/question-generator.ts"
      provides: "Core generation logic with per-category parallel execution and model fallback chain"
      exports: ["generateDiagnosticQuestions"]
    - path: "packages/api/src/mocks/questions.ts"
      provides: "100-question fallback bank (20 per category) with getBalancedQuestions and getMockQuestionsForCategory"
      exports: ["MOCK_QUESTIONS", "getBalancedQuestions", "getMockQuestionsForCategory"]
    - path: "scripts/seed/seed-mock-questions.ts"
      provides: "Script to AI-generate 100 mock questions and write to mocks/questions.ts"
  key_links:
    - from: "packages/ai/src/question-generator.ts"
      to: "packages/ai/src/retrieval.ts"
      via: "supabase.from('content_chunk') query for random chunks by lesson_id prefix"
      pattern: "supabase.*content_chunk.*lesson_id"
    - from: "packages/ai/src/question-generator.ts"
      to: "packages/ai/src/openrouter.ts"
      via: "openrouter.chat.completions.create with response_format json_schema"
      pattern: "openrouter\\.chat\\.completions\\.create"
    - from: "packages/ai/src/question-generator.ts"
      to: "packages/ai/src/question-schema.ts"
      via: "Zod validation of LLM output"
      pattern: "generatedQuestionsArraySchema\\.safeParse"
---

<objective>
Build the AI question generation service that creates diagnostic questions from RAG content chunks via LLM.

Purpose: Replace hardcoded 25 mock questions with LLM-generated questions sourced from 5,291 real lesson chunks. This is the core AI module — Plan 02 will integrate it into the diagnostic router.
Output: question-generator.ts, question-schema.ts, expanded 100-question mock bank, seed script
</objective>

<execution_context>
@C:/Users/Zebrosha/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Zebrosha/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ai-question-generation/02-RESEARCH.md

@packages/ai/src/openrouter.ts
@packages/ai/src/retrieval.ts
@packages/ai/src/generation.ts
@packages/ai/src/index.ts
@packages/shared/src/types/index.ts
@packages/api/src/mocks/questions.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Zod schema, JSON schema, and question generator service</name>
  <files>
    packages/ai/src/question-schema.ts
    packages/ai/src/question-generator.ts
    packages/ai/src/index.ts
  </files>
  <action>
**1. Create `packages/ai/src/question-schema.ts`:**

Zod schema for runtime validation of LLM output:
- `generatedQuestionSchema`: z.object with question (string, min 10, max 500), options (array of 4 strings, min 1 max 300 each), correctIndex (int 0-3), explanation (string, min 10, max 500), difficulty (enum EASY/MEDIUM/HARD)
- `generatedQuestionsArraySchema`: z.object with questions array (min 1, max 5)
- `questionJsonSchema`: Plain JSON Schema object mirroring the Zod schema for OpenRouter `response_format: { type: "json_schema" }`. Must have `additionalProperties: false` at all levels, all fields required.
- Export `GeneratedQuestion` type inferred from Zod.

**2. Create `packages/ai/src/question-generator.ts`:**

Core exports:
- `CATEGORY_TO_COURSES` map: `{ ANALYTICS: ['01_analytics'], MARKETING: ['02_ads', '05_ozon'], CONTENT: ['03_ai'], OPERATIONS: ['04_workshops', '06_express'], FINANCE: [] }`
- `generateDiagnosticQuestions()`: Main entry point, returns `Promise<DiagnosticQuestion[]>` (15 questions).

Implementation details:
- Use `Promise.allSettled` to generate 3 questions per category in parallel (5 LLM calls).
- For each category, call `generateQuestionsForCategory(category, 3)`.
- If a category's generation fails (rejected or wrong count), substitute with `getMockQuestionsForCategory(category, 3)` from mocks/questions.ts.
- Shuffle final 15 questions before returning.

`generateQuestionsForCategory(category, count)`:
- If `CATEGORY_TO_COURSES[category]` is empty (FINANCE), throw immediately to trigger mock fallback.
- Fetch random chunks: query `supabase.from('content_chunk')` where `lesson_id` starts with ANY course prefix for that category. Use `.or()` for multiple prefixes (e.g., `lesson_id.like.02_ads%,lesson_id.like.05_ozon%` for MARKETING). Fetch `count * 3` chunks (15), randomly sample `5` in JS.
- Build system prompt (from RESEARCH.md): 70% practical cases, 30% theory, Russian language, mix of EASY/MEDIUM/HARD.
- User message: concatenate chunk contents as context.
- Call LLM with model fallback chain:
  - Primary: `MODELS.chat` (gemini-2.5-flash) with 8s timeout via `{ timeout: 8000 }` option.
  - If fails (timeout, parse error, validation fail): try `MODELS.fallback` (gpt-4o-mini) with 8s timeout.
  - If both fail: throw Error (caller substitutes mock).
- Use `response_format: { type: "json_schema", json_schema: { name: "diagnostic_questions", strict: true, schema: questionJsonSchema } }`.
- Parse JSON response. Strip markdown code fences (```` ```json ... ``` ````) before JSON.parse if present.
- Validate with `generatedQuestionsArraySchema.safeParse()`.
- If validation fails, throw (triggers next model in chain or mock fallback).
- Map validated questions to `DiagnosticQuestion` format: add `id` (generate with `q-${category.toLowerCase()}-${Date.now()}-${i}`), add `skillCategory: category`.
- **Shuffle options array** and recalculate `correctIndex` to avoid LLM index bias.
- Set `temperature: 0.7`, `max_tokens: 2048`.

**3. Update `packages/ai/src/index.ts`:**

Add exports:
```typescript
// Question generation
export { generateDiagnosticQuestions, CATEGORY_TO_COURSES } from './question-generator';
export { generatedQuestionSchema, generatedQuestionsArraySchema, questionJsonSchema } from './question-schema';
export type { GeneratedQuestion } from './question-schema';
```

Import `getMockQuestionsForCategory` from `@mpstats/api` is NOT possible (circular dep). Instead, pass mock questions as a parameter or import from a shared location. **Decision:** The question-generator.ts should accept an optional `getMockQuestions` callback parameter. Default to throwing if no callback provided. The diagnostic router (Plan 02) will inject the mock function.

Actually, simpler approach per research: question-generator.ts throws on failure, the caller in diagnostic router catches and substitutes mock. This avoids circular deps entirely. The `generateDiagnosticQuestions()` function should accept a `fallbackFn: (category: SkillCategory, count: number) => DiagnosticQuestion[]` parameter that provides mock questions for failed categories.
  </action>
  <verify>
- `pnpm --filter @mpstats/ai typecheck` passes
- Manual review: question-schema.ts exports Zod + JSON Schema, question-generator.ts exports generateDiagnosticQuestions
- Verify CATEGORY_TO_COURSES has FINANCE: [] (empty — always falls back)
  </verify>
  <done>
- question-schema.ts has Zod schema matching DiagnosticQuestion interface from @mpstats/shared
- question-generator.ts implements per-category parallel generation with Promise.allSettled
- Model fallback chain: primary -> fallback -> throw (for mock substitution by caller)
- Options shuffled after LLM generation
- FINANCE category handled (empty courses array -> immediate throw)
- index.ts re-exports new modules
  </done>
</task>

<task type="auto">
  <name>Task 2: Expanded 100-question mock bank and seed script</name>
  <files>
    packages/api/src/mocks/questions.ts
    scripts/seed/seed-mock-questions.ts
  </files>
  <action>
**1. Create `scripts/seed/seed-mock-questions.ts`:**

AI-powered seed script that generates 100 mock questions (20 per category) and writes them to `packages/api/src/mocks/questions.ts`.

Implementation:
- Load env vars manually (same pattern as `seed-skill-categories.ts` from Phase 1 — read `.env` file, parse key=value).
- Initialize OpenRouter client directly (same as packages/ai/src/openrouter.ts pattern).
- For each of 5 categories, call LLM to generate 20 questions:
  - Use `response_format: { type: "json_schema" }` with the same schema.
  - System prompt: same as question-generator.ts but explicitly request 20 questions, mix 70/30 practical/theory per user decision, EASY/MEDIUM/HARD mix (~7/7/6 per category).
  - For categories with courses (ANALYTICS, MARKETING, CONTENT, OPERATIONS): fetch ~20 random chunks from Supabase as context.
  - For FINANCE (no course): prompt without chunk context, instruct LLM to create marketplace finance questions (unit-economics, ROI, margins, commissions).
- Validate each batch with Zod.
- Assign sequential IDs: `q-{category}-{1..20}`.
- Write output as TypeScript file with proper formatting.
- Support `--dry-run` flag (print to console, don't write file).

**2. Replace `packages/api/src/mocks/questions.ts`:**

After seed script runs, the file will contain 100 questions. But for now, manually expand the current 25 questions to a proper 100-question bank. Structure:

- Keep the `DiagnosticQuestion[]` array format.
- Add `getMockQuestionsForCategory(category: SkillCategory, count: number): DiagnosticQuestion[]` export. This selects `count` random questions from the given category.
- Keep existing `getBalancedQuestions(count)` for backward compatibility.
- The actual 100 questions will be generated by running the seed script, but provide a reasonable starting set by duplicating/expanding current 25 to ensure 20 per category exist. Mark with TODO comment that these should be replaced by running `pnpm tsx scripts/seed/seed-mock-questions.ts`.

Key: `getMockQuestionsForCategory` must be exported for use by question-generator.ts fallback mechanism in Plan 02.

Note: The seed script generates questions but user decision says "questions reviewed by human before inclusion." So the script writes to a staging file or the user reviews the output before committing. Add `--output` flag to seed script: default writes to `packages/api/src/mocks/questions.generated.ts`, user reviews and renames.
  </action>
  <verify>
- `pnpm --filter @mpstats/api typecheck` passes (if applicable) or `npx tsc --noEmit` on the mocks file
- `getMockQuestionsForCategory('ANALYTICS', 3)` returns 3 questions (verify via quick test in script)
- `getBalancedQuestions(15)` returns 15 questions with 3 per category
- seed-mock-questions.ts compiles: `npx tsc --noEmit scripts/seed/seed-mock-questions.ts` or check with tsx
  </verify>
  <done>
- mocks/questions.ts has 100 questions (20 per category) with proper IDs
- getMockQuestionsForCategory exported and working
- getBalancedQuestions backward compatible
- seed-mock-questions.ts ready to run for regenerating questions
- All FINANCE questions present (20) despite no course data
  </done>
</task>

</tasks>

<verification>
1. `pnpm --filter @mpstats/ai typecheck` — no errors
2. `pnpm --filter @mpstats/api typecheck` — no errors (if tRPC routers import mock functions)
3. question-generator.ts correctly handles FINANCE (empty CATEGORY_TO_COURSES) by throwing immediately
4. question-schema.ts JSON Schema matches Zod schema (both enforce 4 options, correctIndex 0-3)
5. Mock bank has exactly 100 questions, 20 per category
6. Options shuffle logic preserves correctIndex mapping
</verification>

<success_criteria>
- AI question generation module exists and exports generateDiagnosticQuestions()
- Zod + JSON Schema validation pipeline ready
- 100-question mock bank replaces old 25-question set
- Seed script exists for regenerating mock questions via LLM
- All typecheck passes
</success_criteria>

<output>
After completion, create `.planning/phases/02-ai-question-generation/02-01-SUMMARY.md`
</output>
